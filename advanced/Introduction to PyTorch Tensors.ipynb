{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lJ3c8uvK7ap5"},"outputs":[],"source":["import torch\n","import math"]},{"cell_type":"markdown","source":["**PyTorch Tensors**: Tensors are the central data abstraction in PyTorch."],"metadata":{"id":"fIgb-Z1TAGux"}},{"cell_type":"markdown","source":["\n","**Creating Tensors**: The simplest way to create a tensor is with the torch.empty() call:"],"metadata":{"id":"OFOTFhDRATvm"}},{"cell_type":"code","source":["x = torch.empty(3, 4)\n","print(type(x))\n","print(x)\n","#The torch.empty() call allocates memory for the tensor, but does not initialize it with any values."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KFDkj19TAQno","outputId":"9edba571-72da-42a6-98b7-eab7cf0c7cdb","executionInfo":{"status":"ok","timestamp":1706858616869,"user_tz":-330,"elapsed":472,"user":{"displayName":"Jasmine Das","userId":"11422717978872947447"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'>\n","tensor([[3.4578e-06, 4.3198e-41, 3.4578e-06, 4.3198e-41],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"]}]},{"cell_type":"code","source":["#More often than not, you’ll want to initialize your tensor with some value.\n","#Common cases are all zeros, all ones, or random values,\n","zeros = torch.zeros(2, 3)\n","print(zeros)\n","\n","ones = torch.ones(2, 3)\n","print(ones)\n","\n","torch.manual_seed(1729)\n","random = torch.rand(2, 3)\n","print(random)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-KQFqb2O-PK3","outputId":"0815199e-c743-4150-907e-de7b00c79670","executionInfo":{"status":"ok","timestamp":1706858629156,"user_tz":-330,"elapsed":518,"user":{"displayName":"Jasmine Das","userId":"11422717978872947447"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n","tensor([[1., 1., 1.],\n","        [1., 1., 1.]])\n","tensor([[0.3126, 0.3791, 0.3087],\n","        [0.0736, 0.4216, 0.0691]])\n"]}]},{"cell_type":"code","source":["#We call the .empty_like(), .zeros_like(), .ones_like(), and .rand_like() methods.\n","#Using the .shape property, we can verify that each of these methods returns a tensor of identical dimensionality and extent.\n","x = torch.empty(2, 2, 3)\n","print(x.shape)\n","print(x)\n","\n","empty_like_x = torch.empty_like(x)\n","print(empty_like_x.shape)\n","print(empty_like_x)\n","\n","zeros_like_x = torch.zeros_like(x)\n","print(zeros_like_x.shape)\n","print(zeros_like_x)\n","\n","ones_like_x = torch.ones_like(x)\n","print(ones_like_x.shape)\n","print(ones_like_x)\n","\n","rand_like_x = torch.rand_like(x)\n","print(rand_like_x.shape)\n","print(rand_like_x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4DMRFLmWBKMk","outputId":"b0d6989e-d0ad-45d2-df0d-ab8ef0057600","executionInfo":{"status":"ok","timestamp":1706858633238,"user_tz":-330,"elapsed":518,"user":{"displayName":"Jasmine Das","userId":"11422717978872947447"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 2, 3])\n","tensor([[[-4.4341e+09,  3.3448e-41, -4.4163e+09],\n","         [ 3.3448e-41,  1.3563e-19,  1.1632e+33]],\n","\n","        [[ 1.6529e+19,  1.6676e+19,  7.1450e+31],\n","         [ 3.9173e-02,  1.0658e-32,  1.3563e-19]]])\n","torch.Size([2, 2, 3])\n","tensor([[[-4.4427e+09,  3.3448e-41, -4.4366e+09],\n","         [ 3.3448e-41,  7.0065e-45,  7.0065e-45]],\n","\n","        [[ 1.4013e-45,  0.0000e+00, -4.4426e+09],\n","         [ 3.3448e-41, -4.4426e+09,  3.3448e-41]]])\n","torch.Size([2, 2, 3])\n","tensor([[[0., 0., 0.],\n","         [0., 0., 0.]],\n","\n","        [[0., 0., 0.],\n","         [0., 0., 0.]]])\n","torch.Size([2, 2, 3])\n","tensor([[[1., 1., 1.],\n","         [1., 1., 1.]],\n","\n","        [[1., 1., 1.],\n","         [1., 1., 1.]]])\n","torch.Size([2, 2, 3])\n","tensor([[[0.2332, 0.4047, 0.2162],\n","         [0.9927, 0.4128, 0.5938]],\n","\n","        [[0.6128, 0.1519, 0.0453],\n","         [0.5035, 0.9978, 0.3884]]])\n"]}]},{"cell_type":"markdown","source":["**Tensor Data Types**:\n","Available data types include:\n","\n","torch.bool\n","\n","torch.int8\n","\n","torch.uint8\n","\n","torch.int16\n","\n","torch.int32\n","\n","torch.int64\n","\n","torch.half\n","\n","torch.float\n","\n","torch.double\n","\n","torch.bfloat\n","Setting the datatype of a tensor is possible a couple of ways:"],"metadata":{"id":"g_fDZsd9DXfs"}},{"cell_type":"code","source":["#1. The simplest way to set the underlying data type of a tensor is with an optional argument at creation time.\n","a = torch.ones((2, 3), dtype=torch.int16)\n","print(a)\n","\n","b = torch.rand((2, 3), dtype=torch.float64) * 20.\n","print(b)\n","# 2. The other way to set the datatype is with the .to() method.\n","c = b.to(torch.int32)\n","print(c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"awCl86cjDOho","outputId":"f28e6eac-a651-4a7b-e4fd-25be1fb13a11","executionInfo":{"status":"ok","timestamp":1706858639806,"user_tz":-330,"elapsed":629,"user":{"displayName":"Jasmine Das","userId":"11422717978872947447"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 1, 1],\n","        [1, 1, 1]], dtype=torch.int16)\n","tensor([[10.8626,  2.1505, 19.6913],\n","        [ 0.9956,  1.4148,  5.8364]], dtype=torch.float64)\n","tensor([[10,  2, 19],\n","        [ 0,  1,  5]], dtype=torch.int32)\n"]}]},{"cell_type":"markdown","source":["**Math & Logic with PyTorch Tensors**"],"metadata":{"id":"RcstcDENEVRR"}},{"cell_type":"code","source":["#1. Airthmetic with scalars\n","ones = torch.zeros(2, 2) + 1\n","twos = torch.ones(2, 2) * 2\n","threes = (torch.ones(2, 2) * 7 - 1) / 2\n","fours = twos ** 2\n","sqrt2s = twos ** 0.5\n","\n","print(ones)\n","print(twos)\n","print(threes)\n","print(fours)\n","print(sqrt2s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FiSEWaz_DdZj","outputId":"b5811c5a-c336-4fc5-9b5f-7d8b565c406f","executionInfo":{"status":"ok","timestamp":1706858645520,"user_tz":-330,"elapsed":502,"user":{"displayName":"Jasmine Das","userId":"11422717978872947447"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1.],\n","        [1., 1.]])\n","tensor([[2., 2.],\n","        [2., 2.]])\n","tensor([[3., 3.],\n","        [3., 3.]])\n","tensor([[4., 4.],\n","        [4., 4.]])\n","tensor([[1.4142, 1.4142],\n","        [1.4142, 1.4142]])\n"]}]},{"cell_type":"code","source":["#2. Similar operations between two tensors\n","powers2 = twos ** torch.tensor([[1, 2], [3, 4]])\n","print(powers2)\n","\n","fives = ones + fours\n","print(fives)\n","\n","dozens = threes * fours\n","print(dozens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fwwk_GnNEg8C","outputId":"8466b3a7-70e3-4296-ce4b-b26b3e9923c9","executionInfo":{"status":"ok","timestamp":1706858649128,"user_tz":-330,"elapsed":8,"user":{"displayName":"Jasmine Das","userId":"11422717978872947447"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 2.,  4.],\n","        [ 8., 16.]])\n","tensor([[5., 5.],\n","        [5., 5.]])\n","tensor([[12., 12.],\n","        [12., 12.]])\n"]}]},{"cell_type":"code","source":["#3. Tensor Broadcasting\n","# Same rule as broadcasting\n","rand = torch.rand(2, 4)\n","doubled = rand * (torch.ones(1, 4) * 2)\n","\n","print(rand)\n","print(doubled)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sM2kiF6MFC53","outputId":"536b4108-70f7-4570-d441-12850317f635","executionInfo":{"status":"ok","timestamp":1706858652858,"user_tz":-330,"elapsed":514,"user":{"displayName":"Jasmine Das","userId":"11422717978872947447"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.0703, 0.5105, 0.9451, 0.2359],\n","        [0.1979, 0.3327, 0.6146, 0.5999]])\n","tensor([[0.1405, 1.0210, 1.8901, 0.4717],\n","        [0.3959, 0.6655, 1.2291, 1.1998]])\n"]}]},{"cell_type":"markdown","source":["The rules for broadcasting are:\n","\n","Each tensor must have at least one dimension - no empty tensors.\n","\n","Comparing the dimension sizes of the two tensors, going from last to first:\n","\n","Each dimension must be equal, or\n","\n","One of the dimensions must be of size 1, or\n","\n","The dimension does not exist in one of the tensors"],"metadata":{"id":"kkR5eJbRGG4Z"}},{"cell_type":"code","source":["a =     torch.ones(4, 3, 2)\n","\n","b = a * torch.rand(   3, 2) # 3rd & 2nd dims identical to a, dim 1 absent\n","print(b)\n","\n","c = a * torch.rand(   3, 1) # 3rd dim = 1, 2nd dim identical to a\n","print(c)\n","\n","d = a * torch.rand(   1, 2) # 3rd dim identical to a, 2nd dim = 1\n","print(d)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2KfJqBcFF9GT","outputId":"c2629bc9-84bf-4540-acec-1c70ea6257ad","executionInfo":{"status":"ok","timestamp":1706858655365,"user_tz":-330,"elapsed":6,"user":{"displayName":"Jasmine Das","userId":"11422717978872947447"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[0.5013, 0.9397],\n","         [0.8656, 0.5207],\n","         [0.6865, 0.3614]],\n","\n","        [[0.5013, 0.9397],\n","         [0.8656, 0.5207],\n","         [0.6865, 0.3614]],\n","\n","        [[0.5013, 0.9397],\n","         [0.8656, 0.5207],\n","         [0.6865, 0.3614]],\n","\n","        [[0.5013, 0.9397],\n","         [0.8656, 0.5207],\n","         [0.6865, 0.3614]]])\n","tensor([[[0.6493, 0.6493],\n","         [0.2633, 0.2633],\n","         [0.4762, 0.4762]],\n","\n","        [[0.6493, 0.6493],\n","         [0.2633, 0.2633],\n","         [0.4762, 0.4762]],\n","\n","        [[0.6493, 0.6493],\n","         [0.2633, 0.2633],\n","         [0.4762, 0.4762]],\n","\n","        [[0.6493, 0.6493],\n","         [0.2633, 0.2633],\n","         [0.4762, 0.4762]]])\n","tensor([[[0.0548, 0.2024],\n","         [0.0548, 0.2024],\n","         [0.0548, 0.2024]],\n","\n","        [[0.0548, 0.2024],\n","         [0.0548, 0.2024],\n","         [0.0548, 0.2024]],\n","\n","        [[0.0548, 0.2024],\n","         [0.0548, 0.2024],\n","         [0.0548, 0.2024]],\n","\n","        [[0.0548, 0.2024],\n","         [0.0548, 0.2024],\n","         [0.0548, 0.2024]]])\n"]}]},{"cell_type":"code","source":["a =     torch.ones(4, 3, 2)\n","\n","b = a * torch.rand(4, 3)    # dimensions must match last-to-first\n","\n","c = a * torch.rand(   2, 3) # both 3rd & 2nd dims different\n","\n","d = a * torch.rand((0, ))   # can't broadcast with an empty tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":251},"id":"S6Az4BVGGJ7r","outputId":"c9d21717-c1c7-47a3-fefd-1c6bc6009aca"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-591adab00a90>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# dimensions must match last-to-first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m   \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# both 3rd & 2nd dims different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2"]}]},{"cell_type":"markdown","source":["**More Mathematical Functions**"],"metadata":{"id":"KxfL4pYfGo5E"}},{"cell_type":"code","source":["# common functions\n","a = torch.rand(2, 4) * 2 - 1\n","print('Common functions:')\n","print(torch.abs(a))\n","print(torch.ceil(a))\n","print(torch.floor(a))\n","print(torch.clamp(a, -0.5, 0.5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8c5EjOkzGPB6","outputId":"e11830f8-a9a7-4c5b-92de-3fd8c12afe5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Common functions:\n","tensor([[0.9755, 0.9295, 0.8190, 0.1029],\n","        [0.7480, 0.4949, 0.3846, 0.5091]])\n","tensor([[1., -0., -0., -0.],\n","        [1., -0., 1., 1.]])\n","tensor([[ 0., -1., -1., -1.],\n","        [ 0., -1.,  0.,  0.]])\n","tensor([[ 0.5000, -0.5000, -0.5000, -0.1029],\n","        [ 0.5000, -0.4949,  0.3846,  0.5000]])\n"]}]},{"cell_type":"code","source":["# trigonometric functions and their inverses\n","angles = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n","sines = torch.sin(angles)\n","inverses = torch.asin(sines)\n","print('\\nSine and arcsine:')\n","print(angles)\n","print(sines)\n","print(inverses)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KzSH4zo6I1qD","outputId":"f68838b0-2031-4b75-fcb3-432977f2fb8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Sine and arcsine:\n","tensor([0.0000, 0.7854, 1.5708, 2.3562])\n","tensor([0.0000, 0.7071, 1.0000, 0.7071])\n","tensor([0.0000, 0.7854, 1.5708, 0.7854])\n"]}]},{"cell_type":"code","source":["# bitwise operations\n","print('\\nBitwise XOR:')\n","b = torch.tensor([1, 5, 11])\n","c = torch.tensor([2, 7, 10])\n","print(torch.bitwise_xor(b, c))\n","\n","# comparisons:\n","print('\\nBroadcasted, element-wise equality comparison:')\n","d = torch.tensor([[1., 2.], [3., 4.]])\n","e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n","print(torch.eq(d, e)) # returns a tensor of type bool\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mcfym8a_I83e","outputId":"2bf73cff-6885-4d8f-f350-45987c6a3551"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Bitwise XOR:\n","tensor([3, 2, 1])\n","\n","Broadcasted, element-wise equality comparison:\n","tensor([[ True, False],\n","        [False, False]])\n"]}]},{"cell_type":"code","source":["# reductions:\n","print('\\nReduction ops:')\n","print(torch.max(d))        # returns a single-element tensor\n","print(torch.max(d).item()) # extracts the value from the returned tensor\n","print(torch.mean(d))       # average\n","print(torch.std(d))        # standard deviation\n","print(torch.prod(d))       # product of all numbers\n","print(torch.unique(torch.tensor([1, 2, 1, 2, 1, 2]))) # filter unique elements"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tliyID3PJH3E","outputId":"34a3966e-f1d7-4ac9-fdd9-d0b77b21957e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Reduction ops:\n","tensor(4.)\n","4.0\n","tensor(2.5000)\n","tensor(1.2910)\n","tensor(24.)\n","tensor([1, 2])\n"]}]},{"cell_type":"code","source":["# vector and linear algebra operations\n","v1 = torch.tensor([1., 0., 0.])         # x unit vector\n","v2 = torch.tensor([0., 1., 0.])         # y unit vector\n","m1 = torch.rand(2, 2)                   # random matrix\n","m2 = torch.tensor([[3., 0.], [0., 3.]]) # three times identity matrix\n","\n","print('\\nVectors & Matrices:')\n","print(torch.cross(v2, v1)) # negative of z unit vector (v1 x v2 == -v2 x v1)\n","print(m1)\n","m3 = torch.matmul(m1, m2)\n","print(m3)                  # 3 times m1\n","print(torch.svd(m3))       # singular value decomposition"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5d8b09yJMum","outputId":"ff1c18dd-11b1-4517-96ef-e012bcd386a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Vectors & Matrices:\n","tensor([ 0.,  0., -1.])\n","tensor([[0.7746, 0.2330],\n","        [0.8441, 0.9004]])\n","tensor([[2.3237, 0.6990],\n","        [2.5322, 2.7011]])\n","torch.return_types.svd(\n","U=tensor([[-0.5247, -0.8513],\n","        [-0.8513,  0.5247]]),\n","S=tensor([4.3010, 1.0478]),\n","V=tensor([[-0.7847, -0.6199],\n","        [-0.6199,  0.7847]]))\n"]}]},{"cell_type":"markdown","source":["**Altering Tensors in Place**:Most binary operations on tensors will return a third, new tensor. When we say c = a * b (where a and b are tensors), the new tensor c will occupy a region of memory distinct from the other tensors.\n","\n","There are times, though, that you may wish to alter a tensor in place - for example, if you’re doing an element-wise computation where you can discard intermediate values. For this, most of the math functions have a version with an appended underscore (_) that will alter a tensor in place."],"metadata":{"id":"qjeqK4m6JofU"}},{"cell_type":"code","source":["a = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n","print('a:')\n","print(a)\n","print(torch.sin(a))   # this operation creates a new tensor in memory\n","print(a)              # a has not changed\n","\n","b = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n","print('\\nb:')\n","print(b)\n","print(torch.sin_(b))  # note the underscore\n","print(b)              # b has changed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15XB9UuDJRMh","outputId":"712a2dd0-b17c-416f-ff2f-ea27213b4d23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["a:\n","tensor([0.0000, 0.7854, 1.5708, 2.3562])\n","tensor([0.0000, 0.7071, 1.0000, 0.7071])\n","tensor([0.0000, 0.7854, 1.5708, 2.3562])\n","\n","b:\n","tensor([0.0000, 0.7854, 1.5708, 2.3562])\n","tensor([0.0000, 0.7071, 1.0000, 0.7071])\n","tensor([0.0000, 0.7071, 1.0000, 0.7071])\n"]}]},{"cell_type":"code","source":["#For arithmetic operations, there are functions that behave similarly:\n","a = torch.ones(2, 2)\n","b = torch.rand(2, 2)\n","\n","print('Before:')\n","print(a)\n","print(b)\n","print('\\nAfter adding:')\n","print(a.add_(b))\n","print(a)\n","print(b)\n","print('\\nAfter multiplying')\n","print(b.mul_(b))\n","print(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VM1eqY7iJ2Sq","outputId":"6be36119-eb80-468a-b112-e57c47c65bf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Before:\n","tensor([[1., 1.],\n","        [1., 1.]])\n","tensor([[0.3995, 0.6324],\n","        [0.9464, 0.0113]])\n","\n","After adding:\n","tensor([[1.3995, 1.6324],\n","        [1.9464, 1.0113]])\n","tensor([[1.3995, 1.6324],\n","        [1.9464, 1.0113]])\n","tensor([[0.3995, 0.6324],\n","        [0.9464, 0.0113]])\n","\n","After multiplying\n","tensor([[1.5959e-01, 3.9991e-01],\n","        [8.9568e-01, 1.2838e-04]])\n","tensor([[1.5959e-01, 3.9991e-01],\n","        [8.9568e-01, 1.2838e-04]])\n"]}]},{"cell_type":"markdown","source":["\n","**Moving to GPU**:One of the major advantages of PyTorch is its robust acceleration on CUDA-compatible Nvidia GPUs. (“CUDA” stands for Compute Unified Device Architecture, which is Nvidia’s platform for parallel computing.) So far, everything we’ve done has been on CPU. How do we move to the faster hardware?\n","\n"],"metadata":{"id":"pH0hgxAVLAn7"}},{"cell_type":"code","source":["#First, we should check whether a GPU is available, with the is_available() method.\n","if torch.cuda.is_available():\n","    print('We have a GPU!')\n","else:\n","    print('Sorry, CPU only.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s_VNQA8-KCh2","outputId":"01a7c872-7eac-4d56-ba4b-fe4b74787456"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sorry, CPU only.\n"]}]},{"cell_type":"markdown","source":["Once we’ve determined that one or more GPUs is available, we need to put our data someplace where the GPU can see it. Your CPU does computation on data in your computer’s RAM. Your GPU has dedicated memory attached to it. Whenever you want to perform a computation on a device, you must move all the data needed for that computation to memory accessible by that device. (Colloquially, “moving the data to memory accessible by the GPU” is shorted to, “moving the data to the GPU”.)"],"metadata":{"id":"kbegbCSSLnsS"}},{"cell_type":"code","source":["#There are multiple ways to get your data onto your target device. You may do it at creation time:\n","if torch.cuda.is_available():\n","    gpu_rand = torch.rand(2, 2, device='cuda')\n","    print(gpu_rand)\n","else:\n","    print('Sorry, CPU only.')\n","#You can query the number of GPUs with torch.cuda.device_count().\n","#If you have more than one GPU, you can specify them by index: device='cuda:0', device='cuda:1', etc."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v0a-x61fKbIs","outputId":"0310d02b-c54d-46e2-af52-0c58d3b49d18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sorry, CPU only.\n"]}]},{"cell_type":"markdown","source":["As a coding practice, specifying our devices everywhere with string constants is pretty fragile. In an ideal world, your code would perform robustly whether you’re on CPU or GPU hardware. You can do this by creating a device handle that can be passed to your tensors instead of a string:"],"metadata":{"id":"hr9ykvbwMLCQ"}},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    my_device = torch.device('cuda')\n","else:\n","    my_device = torch.device('cpu')\n","print('Device: {}'.format(my_device))\n","\n","x = torch.rand(2, 2, device=my_device)\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6mJ1XcwL1_3","outputId":"0dfc741d-613c-4840-e9e3-b11c7f83597e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cpu\n","tensor([[0.3449, 0.1340],\n","        [0.4216, 0.1073]])\n"]}]},{"cell_type":"code","source":["#If you have an existing tensor living on one device, you can move it to another with the to() method.\n","y = torch.rand(2, 2)\n","y = y.to(my_device)"],"metadata":{"id":"AsdKcxgkMRf6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#It is important to know that in order\n","#to do computation involving two or more tensors, all of the tensors must be on the same device.\n","x = torch.rand(2, 2)\n","y = torch.rand(2, 2, device='gpu')\n","z = x + y  # exception will be thrown"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":251},"id":"6DhKzU6nPI_9","outputId":"c791cf6c-307a-4daa-8406-7cf4a4dbc3f7"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-22e85028f645>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#to do computation involving two or more tensors, all of the tensors must be on the same device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m  \u001b[0;31m# exception will be thrown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu"]}]}]}